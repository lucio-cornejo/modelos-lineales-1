---
title: "Trabajo final"
author: "Lucio Enrique Cornejo Ramírez"
date: "`r Sys.Date()`"
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    theme: united
    highlight-style: tango
    toc-float: 
      collapsed: false
      smooth-scroll: true
    
  # pdf:
  #   toc: true
  #   toc-depth: 3
  #   number-sections: true
  #   highlight-style: tango
  #   keep-tex: true

execute: 
  cache: true

editor:
  markdown:
    wrap: 120

knitr:
  opts_chunk: 
    warning: false
    message: false
---

## Introducción

### Marco del problema

Entre los costos que más desastibilizan económicamente a las personas, se encuentra el pago por procedimientos médicos.
Estos precios pueden variar en gran medida dependiendo de 
características del paciente, como detallaremos más adelante.

En ese sentido, resulta de gran valor predecir adecuadamente el costo que un seguro médico cubrirá, respecto a un procedimiento médico. 
Para un paciente, aquella predicción puede servir para 
que planifique qué tanto sería desestabilizado económicamente 
debido a algún tipo de procedimiento particular.
Por otro lado, también para las aseguradoras resulta útil aquellas predicciones, ya que pueden anticipar qué tanto dinero
estarían perdiendo por el monto a cubrir de la operación;
además, con ese conocimiento pueden monitorear mejor qué pedidos
de cobertura resultan anómalos, potencialmente fraudulentos.

### Plan de modelamiento

Anteriormente, hemos planteado como variable por predecir a la
cantidad monetaria que la aseguradora de un paciente cubrirá
debido a un procedimiento médico.
Note que aquel monto está muy relacionado al precio que paga el
paciente luego que el seguro descuenta parte del costo del procedimiento médico 
... ese monto, que denominaremos `charges`, se intentará predecir.

Asimismo, vale recalcar la influencia de los gastos del hospital debido al procedimiento médico, variable que denotaremos `Hospital_expenditure`,
sobre `charges`.

Para el modelamiento, se considerará además las siguientes características del paciente:

  - Sexo (`age`)
  - Si fuma o no (`smoker`)
  - Región de la que provee (`region`)
  - Edad (`age`)
  - Índice de masa corporal (`bmi`)
  - Cantidad de hijos e hijas (`children`)
  - Costo médico que pagaría en caso no se aplicase seguro médico (`Claim_Amount`)
  - Número de procedimientos pasados (`past_consultations`)
  - Número de pasos que realizó en cierto día (`num_of_steps`)
  - Número de veces que ha sido hospitalizado (`Number_of_past_hospitalizations`)
  - Salario anual (`Anual_Salary`)


## Materiales y métodos

### Datos/Observaciones

Las observaciones que consideraremos para este proyecto fueron descargadas de este sitio [web](https://www.kaggle.com/datasets/shubhamsingh57/ml-model-practice-linear-regression/data).


Estos datos son de distintos pacientes que recibieron algún tipo de tratamiento médico, de los cuales se tienen variables recopiladas, como edad, sexo, si fuma o no, etc.
Así, descartamos que los datos consistan de una serie de tiempo.

No obstante, aquella página web no provee información 
más específica sobre el origen de los datos. Por ejemplo, si han sido recopilados en un único hospital, o en diversos hospitales, pero de qué país,
etc.

Aún así, en esta investigación, no solo se considera la predicción
de la variable mencionada, sino también cómo es que influyen las variables que emplearemos como regresores, en la predicción final.
Por ejemplo, si su relación es directa o inversamente proporcional.

A continuación justificamos el posible uso de los
caracteres presentes en los datos, como covariables:

  - **Sexo**: Debido al riesgo y costos distintos entre hombres y mujeres, para ciertos tipos de operaciones; por ejemplo, parto.
  - **Si fuma o no**: Pues fumar aumenta la probabilidad de desarrollar complicaciones médicas
  - **Región de la que provee**: Ya que el costo de un procedimiento médico puede variar mucho por región, así que también varía cuánto cubriría una aseguradora.
  - **Edad**: Puesto que pacientes mayores suelen requerir más cuidados.
  - **Índice de masa corporal**: En base a que un IMC elevado está asociado a mayores riesgos durante cirugías.
  - **Cantidad de hijos e hijas**: Esto puede influir en el tipo de cobertura familiar (de seguro) que tiene el paciente.
  - **Costo médico que pagaría en caso no se aplicase seguro médico**: Importante incluirlo, pues incluso se espera que presente una fuerte correlación positiva con la variable por predecir.
  - **Número de procedimientos pasados**: Puede resultar útil en base a que pacientes con muchos procedimientos suelen tener enfermedades crónicas, por lo que se esperaría una mayor cobertura.
  - **Número de pasos que realizó en cierto día**: Esta variable tampoco se explica en la fuente, pero la podemos considerar como una medida de la condición física de una persona, qué tan activa es.
  - **Número de veces que ha sido hospitalizado**: Pues más hospitalizaciones implican mayor riesgo en la operación, aumentando posiblemente así los costos que cubre la aseguradora.
  - **Salario anual**: Como indicador de nivel socioeconómico, se espera que pacientes con ingresos altos cuenten con aseguradoras que cubren mayor parte el costo por intervención médica.

### Itinerario metodológico de la modelización

A continuación, describrimos los pasos a seguir para la construcción de diferentes modelos de predicción:

1. Descarte de observaciones que presenten algún valor faltante para cualquier variable.
1. Gráficos de dispersión para pares de variables
1. Debido al máximo establecido en este proyecto, respecto al número de covariables, calculamos las correlaciones múltiples 
1. Filtro de observaciones al azar, debido a máximo
establecido en este proyecto.

1. Limpieza de datos
1. Construcción del modelo OLS, empleando todas las
covariables
1. Gráficos de valores observados y residuos contra valores estimados. Interpretar R^2

1. Emplear el test de Levine y Shapiro para averiguar la homocedasticidad y la
normalidad.
1. En caso positivo, evaluar por medio de ANOVA si el modelo tiene sentido. En caso positivo, determinar qué variables explicativas tienen sentido.

1. Si se encuentran puntos aberrantes, recorrer el modelo sin aquellos y repetir los pasos mencionados.

1. Ejecutar los tests de tipo ANOVA
1. En caso positivo, incluir los tests post-hoc


## Resultados

### Carga de datos

A continuación, mostramos los datos descargados del sitio web mencionado
en la sección previa.

```{r}
#| output: false
#| warning: false
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
```

```{r}
datos <- readr::read_csv("./new_insurance_data.csv")
dplyr::glimpse(datos)
```

Descartamos las observaciones con alguna variable faltante

```{r}
# Cantidad de observaciones
nrow(datos)

# Cantidad de observaciones con alguna variable faltante
sum(!complete.cases(datos))

datos <- tidyr::drop_na(datos)
```

### Filtro de variables

#### Graficos de dispersión

```{r}
covariables_numericas <- c(
  "age",
  "bmi",
  "children",
  "Claim_Amount",
  "past_consultations",
  "num_of_steps",
  "Hospital_expenditure",
  "Number_of_past_hospitalizations",
  "Anual_Salary"
)
columnas_numericas <- c(covariables_numericas, "charges")

GGally::ggpairs(datos[, columnas_numericas])
```

Nótese que la variable por predecir, `charges`, parece presentar
una relación lineal con la covariable `Annual_Salary`. 
Asimismo, parece haber indicios de que resulta posible transformar
las variables `num_of_steps` y `Hospital_expenditure` por funciones
logaritmo y exponcial, respectivamente, con fin que se tenga una fuerte 
relación lineal entre el predictor creado y la variable por predecir.

#### Correlaciones parciales entre covariables

```{r}
d.cor <- cor(datos[, covariables_numericas])
d.inv <- solve(d.cor)

d.corm <- sqrt(1-1/diag(d.inv))
pd <- length(d.corm)  


d.part <- d.inv
for (i in 1:pd) {
  for (j in 1:(i-1)) {
    d.part[i,j] <- -d.inv[i,j]/sqrt(d.inv[i,i]*d.inv[j,j])
  }
  d.part[i,i] <- d.corm[i]
  d.part[1:(i-1),i] <- d.part[i,1:(i-1)]  
}
d.part
```

```{r}
vals_diag <- diag(d.part)
max_col_indices <- apply(d.part, 1, which.max)
idx_ordenados <- order(vals_diag, decreasing = TRUE)
ordenados_vals_diag <- vals_diag[idx_ordenados]
ordenados_max_cols <- max_col_indices[idx_ordenados]

data.frame(correlacion_parcial = ordenados_vals_diag)
```

Note que cuatro covariables presentan correlación parcial mayor a 0.8,
en orden descendente `Anual_Salary`, `Hospital_expenditure`, `num_of_steps`
y `Number_of_past_hospitalizations`. Aquellas variables son muy explicadas por las demás (posible multicolinearidad).

```{r}
#| echo: false
melt(d.part) |>
  ggplot(aes(Var1, Var2, fill = value)) +
    geom_tile() +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white") +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text.y = element_text(angle = 45, hjust = 1)
    ) +
    labs(
      title = "Correlaciones parciales", 
      x = "Variables", 
      y = "Variables"
    )
```

Inspeccionemos ahora, de manera particular, las correlaciones entre covariables

```{r}
#| echo: false
matriz_cor <- datos |>
  dplyr::select(
    age,
    bmi,
    children,
    Claim_Amount,
    past_consultations,
    num_of_steps,
    Hospital_expenditure,
    Number_of_past_hospitalizations,
    Anual_Salary,
  ) |>
  cor()

melt(matriz_cor) |>
  ggplot(aes(Var1, Var2, fill = value)) +
    geom_tile() +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 45, hjust = 1)
      ) +
    labs(title = "Heatmap de correlación", x = "Variables", y = "Variables")
```

Observamos una alta correlación entre `Anual_Salary` y `Hospital_expenditure`,
con un valor de `r cor(datos$Anual_Salary, datos$Hospital_expenditure)`. Asimismo, como la variable de salario anual es más sencilla de recopilar (por ejemplo, en una encuesta) que la de gasto de hospital, 
descartamos la variable cuantitativa `Hospital_expenditure`.

```{r}
datos |>
  ggplot(aes(x = Anual_Salary, y = Hospital_expenditure)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Salario anual", y = "Gasto del hospital") +
  theme_minimal()
```

#### Variable cuantitativa `num_of_steps`

Inicialmente se consideró descartar la variable referente al número
de pasos que realizó el paciente en cierto día.
Esto pues, a primera vista, no se esperaría que tal información
resulte relevante para el costo final por el procedimiento médico.

Graficamos tal posible regreso contra la variable respuesta:

```{r}
datos |>
  ggplot(aes(x = num_of_steps, y = charges)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Número de pasos", y = "Pago final") +
  theme_minimal()
```

En base a que la relación parece asemejarse a una exponencial,
graficamos la variable `num_of_steps` contra el logaritmo de la variable respuesta:

```{r}
datos |>
  dplyr::mutate(scaled_rsp = log(charges)) |>
  ggplot(aes(x = num_of_steps, y = scaled_rsp)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Número de pasos", y = "Pago final") +
  theme_minimal()
```

En base a que aquella relación parece ser *aproximadamente* lineal,
optamos por no descartar la variable cuantitativa `num_of_steps`.

#### Variable cuantitativa `num_of_steps`

```{r}
datos |>
  ggplot(aes(x = num_of_steps, y = charges)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Número de pasos", y = "Pago final") +
  theme_minimal()
```


#### Variable cuantitativa `age`

```{r}
datos |>
  ggplot(aes(x = age, y = charges)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Edad", y = "Pago final") +
  theme_minimal()
```

#### Variable cuantitativa `bmi`

```{r}
datos |>
  ggplot(aes(x = bmi, y = charges)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Índice de masa corporal", y = "Pago final") +
  theme_minimal()
```

#### Variable cuantitativa `children`

```{r}
datos |>
  ggplot(aes(x = children, y = charges)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Número de hijos", y = "Pago final") +
  theme_minimal()
```

#### Variable cuantitativa `past_consultations`

```{r}
datos |>
  ggplot(aes(x = past_consultations, y = charges)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  labs(x = "Número de procedimientos pasados", y = "Pago final") +
  theme_minimal()
```

Descartamos la variable cuantitativa `children`, pues, 
en base a este simple análisis inicial, no parece indicar algún de tipo de
relación lineal con la variable por predecir. Es más, su gráfico de dispersión
parece sugerir que consideremos a la variable `children` como cualitativa.



### Variables categóricas

Para el filtro de variables categóricas, descartaremos aquella para la
cual las distribuciones de la variable respuesta, respecto a los valores
de aquella variable categórica sean relativamente similares.

#### Variable cualitativa `region`

Inspeccionamos la distribución de la variable respuesta, respecto a los 
valores de la variable categórica `region`.

```{r}
datos |>
  ggplot(aes(x = charges, color = region, fill = region)) +
    geom_density(alpha = 0.4) +
    labs(
      title = "Densidad de 'charges' para cada categoría de 'region'",
      x = "charges",
      y = "Densidad"
    ) +
    theme_minimal()
```

En base a que aquellas funciones densidad no presentan una difencia resaltante,
descartaremos la variable `region`.
De esa manera, las variables cualitativas que emplearemos para esta investigación son solo `sex` y `smoker`.



### Variables finales

- Variables cualitativas: 
    - `sex`
    - `smoker`

- Variables cuantitativas:
    - `age`
    - `bmi`
    - `Claim_Amount`
    - `past_consultations`
    - `num_of_steps`
    - `Number_of_past_hospitalizations`
    - `Anual_Salary`
    - `charges` (**variable respuesta**)

#### Base de datos

La base de datos consiste de `r nrow(datos)` observaciones.
Si eliminamos filas que posean algún dato vacío, se tienen
`r nrow(datos)` observaciones.

Para limitarnos a 500 filas, realizaremos un muestreo:

```{r}
datos_finales <- datos |>
  dplyr::select(
    sex,
    smoker,
    age,
    bmi,
    Claim_Amount,
    past_consultations,
    num_of_steps,
    Number_of_past_hospitalizations,
    Anual_Salary,
    charges
  )


set.seed(1234)
datos_finales <- dplyr::sample_n(datos_finales, 500)

openxlsx::write.xlsx(datos_finales, './datos.xlsx')
```


## Discusión

## Conclusiones



<!-- 
  → preparación de datos 
  → exploración 
  → modelado
  → evaluación
  → diagnóstico
  → mejora del modelo

1. Introducción
Presenta el dataset elegido y el objetivo del análisis.

Describe brevemente las variables y el contexto.

2. Limpieza y preparación de los datos (Clase "Start")
Tratar los valores faltantes:

“Como se resultan dos valores faltantes, se decide de tirar las observaciones correspondientes.”

3. Exploración inicial (Clase 02)
Gráficos de parejas de variables y comentarios:

Esto te ayuda a entender relaciones lineales potenciales, detectar colinealidad y valores extremos.

#####################################################

4. Primer modelo OLS básico (Clase 03)
Resultados del modelo inicial

Tabla de análisis de la varianza (ANOVA)

Plot de valores observados y residuos contra valores estimados

5. Evaluación de significancia (Clase 04)
Estadística F del modelo (p < 5%)

Pruebas t para cada variable (p < 5%)

Comparación de modelos usando el error estándar residual

6. Selección de variables (Clase 05)
Correlación parcial entre variables

Selección hacia adelante, hacia atrás y stepwise en dos modelos distintos

Comparación de los modelos obtenidos: ¿coinciden? ¿cuál parece mejor?

7. Diagnóstico de supuestos (Clase 06 y 07)
Buscar puntos aberrantes y repetir el modelo sin ellos

Tests de supuestos clásicos:

Levene (homocedasticidad)

Shapiro-Wilk (normalidad)

Discusión de cuándo es válido el ANOVA, basado en los supuestos

8. Modelo con interacciones y comparación ANOVAs (Clase 08)
Modelo extendido con interacciones (por ejemplo, con "competición")

Correr y comparar las tres ANOVA (modelo base, con interacción, etc.)

Incluir tests post-hoc si aplica

Evaluar impacto en R², significancia de interacciones, etc.

9. Conclusiones
¿Qué modelo final seleccionas y por qué?

¿Cuáles variables explican mejor la variable respuesta?

Reflexión crítica sobre las limitaciones (validez de supuestos, tamaño muestral, etc.)

-->

<!-- 

## Start

- Como se resultan dos valores faltantes, se decide de tirar las observaciones correspondientes.


## 02

- hacer gráficos de parejas de variables y comentar

## 03

- resultados
- tabla de analisis de la varianza
- el apalancamiento de las unidades
- dos plot de valores observados y residuos contra los valores estimados
- ¿a través de las tablas de análisis de varianza, ¿cual modelo le
parece mejor?
- tirar dos unidades con mayor apalancamiento,
comentar el cambio, incluyendo gráficos con
valores estimados y errores en los dos casos
- mostrar la diferencia entre betas y entre los residuos de los dos modelos.

## 04

- Evaluar si el modelo tiene sentido (Estadística F, umbral 5%) y si todas
las variables explicativas tienen sentido (t de student, umbral 5%).
- Considerando el resíduo promedio (Residual standard error), ¿cual
modelo le parece mejor?

## 05

- ¿cuales son las especialidades mejor explicadas para las demás?
- ¿cuales las parejas con más alta correlación parcial?
- modelar dos especialidades con selección para adelante, para atrás y
stepwise de las demás. ¿Sale el mismo modelo o cual le parece mejor?
- Reporte shown by teacher, en pregunta 9

## 06

- Si se encuentran puntos aberrantes, recorrer el modelo sin esos y hacer
de nuevo todos los test.
- Look for puntos aberrantes, luego recorrer modelo sin ellos

## 07

- qq-plot for residuals
- correr test de Levine y Shapiro para averiguar la homocedasticidad y la
normalidad.
- correr el ANOVA con el modelo lineal si lo test se lo permiten: 
- Comment del profe: `
No siempre se cumplen los requisitos de homocedasticidad y normalidad. Esto limita la aplicación de la anova ya que la estimación de la varianza no es más posible. De consecuencia las probabilidades asociadas a las estadísticas solo cuantifican la relevancia de las diferencias observadas, pero no pueden ser empleadas estadísticamente.

De todo modo, las anovas muestran una calidad muy alta, con un R2
igual a .82, .82, .84 y .85 respectivamente. Este valor mejora mucho cuando se tira el intercepta en el modelo, llegando a 99.7, 99.8, 99.9 y 99.5 respectivamente. La interacción resulta significativa solo para aletas y masa.
`

## 08

- ver cosa cambia, incluyendo interacciones con la competición y correndo las tres anova
- incluir los test post-hoc

-->
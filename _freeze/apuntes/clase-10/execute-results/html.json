{
  "hash": "a6e9342a6969bde9ff657a2876654c2d",
  "result": {
    "engine": "knitr",
    "markdown": "# Modelo Lineal General {-}\n\n## Nota\n\n- La prueba final será a mano y usando R.\n\n## Tareas pendientes\n\n- **Fija**: Demostrar el teorema de Gauss-Markov generalizado.\n- Completar tarea de la clase pasada.\n- **Fija**: Último ejercicio antes de sección *Pruebas de heterocedasticidad y autocorrelación* del PDF de esta clase (*Considere el modelo de regresión lineal simple ...*). Lo más importante en este ejercicio es la interpretación de los \nresultados.\n\n## Modelo con estructura AR(1)\n\n- Los errores tienen la **misma variabilidad**, pero **están correlacionados**,\ntambién de manera **constante**.\n\nUn modelo lineal general con errores AR(1), se caracteriza por\n\n::: {.callout-note}\n### Modelo con estructura AR(1)\n\n$$\n\\Sigma = \\sigma^2 \\mathbf{V} = \\frac{\\sigma^2}{1 - \\rho^2} \n\\begin{pmatrix}\n1 & \\rho & \\rho^2 & \\cdots & \\rho^{n-1} \\\\\n\\rho & 1 & \\rho & \\cdots & \\rho^{n-2} \\\\\n\\rho^2 & \\rho & 1 & \\cdots & \\rho^{n-3} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\rho^{n-1} & \\rho^{n-2} & \\rho^{n-3} & \\cdots & 1\n\\end{pmatrix}\n$$\n\n- $\\rho = \\text{Corr}(\\varepsilon_i, \\varepsilon_{i-1})$, $\\varepsilon_i = \\rho\\varepsilon_{i-1} + u_i$, $u_i \\sim N(0, \\sigma^2)$\n- El $u_i$ es un efecto aleatorio no observable.\n\n- $\\text{Var}(\\varepsilon_i) = \\sigma_\\varepsilon^2 = \\frac{\\sigma^2}{1 - \\rho^2}$. \n\n- Además, $\\text{Cov}(\\varepsilon_i, \\varepsilon_j) = \\rho^{|i-j|}\\sigma_\\varepsilon^2$\n\n:::\n\nEn ese sentido, entre observaciones distantes, es natural suponer que la correlación es **prácticamente cero**,\npor lo cual la covarianza entre observaciones distantes es también casi cero.\n\n- En caso se cumple que **$\\boldsymbol{\\rho}$ sea casi cero**, sería una buena evidencia para\nconcluir que se puede emplear un modelo homocedástico.\n\n- **Idea de verosimilitud**: ¿Cuál debe ser el valor del parámetro, tal para que se haga más posible tal valor del parámetro, dados los datos?\n\n\n### Algoritmo FGLS para AR(1)\n\n- Es el algoritmo más utilizado para AR(1), pero existen otros más sofisticados, que requieren menor tiempo computacional.\n\n\n::: {.callout-note}\n### Algoritmo FGLS\n\n1. Calcular estimador inicial: $\\hat{\\boldsymbol{\\beta}}^{(0)} = (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\mathbf{y} \\Rightarrow \\hat{\\boldsymbol{\\varepsilon}}^{(0)} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}^{(0)}$\n\n2. Estimar $\\rho$ mediante:\n\n$$\n  \\hat{\\rho} = \\frac{\\sum_{t=2}^n \\hat{\\varepsilon}_t \\hat{\\varepsilon}_{t-1}}{\\sum_{t=1}^n \\hat{\\varepsilon}_t^2}\n$$\n\n3. Construir $\\hat{\\mathbf{V}}$ con $\\hat{\\rho}$\n\n4. Re-estimar $\\boldsymbol{\\beta}$:\n\n$$\n  \\hat{\\boldsymbol{\\beta}}^{(1)} = (\\mathbf{X}^\\top\\hat{\\mathbf{V}}^{-1}\\mathbf{X})^{-1}\\mathbf{X}^\\top\\hat{\\mathbf{V}}^{-1}\\mathbf{y}\n$$\n\n5. Iterar hasta convergencia\n\n:::\n\n- **Nota sobre convergencia**: El hecho que la distribución normal solo tenga un óptimo local, y que resulte en un óptimo global,\ngarantiza que este algoritmo converja al óptimo global que buscamos.\n\n\n## Modelo con varianza ponderada\n\nConsideremos el modelo lineal general:\n\n$$\n\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}, \\quad \\boldsymbol{\\varepsilon} \\sim \\mathcal{N}_n(0, \\boldsymbol{\\Sigma})\n$$\n\n::: {.callout-note}\n### WLS, modelo con varianza ponderada\n\nUn modelo lineal general con varianza ponderada, se caracteriza porque $\\boldsymbol{\\Sigma}$ tiene la forma:\n\n$$\n\\boldsymbol{\\Sigma} = \\sigma^2 \\mathbf{W}^{-1}\n$$\n\ndonde $\\mathbf{W} = \\operatorname{diag}(w_1, w_2, \\ldots, w_n)$ es una matriz diagonal conocida o estimable. En este caso:\n\n$$\n\\operatorname{Var}(\\varepsilon_i) = \\frac{\\sigma^2}{w_i}, \\quad i = 1, \\ldots, n\n$$\n:::\n\n- El estimador $\\beta$ es insesgado y eficiente bajo el teorema de Gauss-Markov generalizado.\n\n**Estimación de Pesos (𝐖)** Existen tres métodos principales:\n\n| Método                  | Fórmula                                       |\n|------------------------|-----------------------------------------------|\n| Información externa     | $w_i = n_i$ (para datos agrupados)           |\n| Residuos al cuadrado    | $w_i = 1/\\hat{\\varepsilon}_i^2$              |\n| Modelado de varianza    | $w_i = 1/\\operatorname{Var}(\\varepsilon_i \\mid \\mathbf{x}_i)$ |\n\n\n## Ejercicios y aplicación de AR(1) y WLS\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nlme)\ndata(Orange)\n```\n:::\n\n\n\n\n\n### Modelo WLS (varPower)\n\n- `varPower` explanation:\n  - $\\epsilon_i \\sim N(0, \\sigma^2 v_i^2);\\; v_i = |x_i|^{\\delta}$\n  - $V(\\epsilon_i) = \\sigma^2 |\\text{age}_i|^{2\\delta}$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1_wls <- gls(\n  circumference ~ age,\n  data = Orange,\n  weights = varPower(form = ~ age),\n  method = \"ML\"\n)\nmodelo1_wls\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized least squares fit by maximum likelihood\n  Model: circumference ~ age \n  Data: Orange \n  Log-likelihood: -146.4082\n\nCoefficients:\n(Intercept)         age \n 18.6151544   0.1034356 \n\nVariance function:\n Structure: Power of variance covariate\n Formula: ~age \n Parameter estimates:\n   power \n1.213287 \nDegrees of freedom: 35 total; 33 residual\nResidual standard error: 0.005402966 \n```\n\n\n:::\n:::\n\n\n\n\n\n### Modelo WLS (varPower) por tipo de árbol\n\n- `varPower` explanation:\n  - $\\epsilon_i \\sim N(0, \\sigma^2 v_i^2)$\n  - $V(\\epsilon_{ij}) = \\sigma^2 |\\text{age}_i|^{2\\delta_{j}}$\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo2_wls <- gls(\n  circumference ~ age,\n  data = Orange,\n  weights = varPower(form = ~ age|Tree),\n  method = \"ML\"\n)\nmodelo2_wls\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized least squares fit by maximum likelihood\n  Model: circumference ~ age \n  Data: Orange \n  Log-likelihood: -139.3749\n\nCoefficients:\n(Intercept)         age \n19.83537254  0.08725257 \n\nVariance function:\n Structure: Power of variance covariate, different strata\n Formula: ~age | Tree \n Parameter estimates:\n       1        2        3        4        5 \n1.098787 1.333910 1.144914 1.341473 1.212303 \nDegrees of freedom: 35 total; 33 residual\nResidual standard error: 0.004057222 \n```\n\n\n:::\n:::\n\n\n\n\n\n### Modelo AR(1)\n\n- `corAR1` explanation:\n  - $\\text{cov}(\\epsilon_i, \\epsilon_{j}) = \\sigma_{\\epsilon}^2 \\rho^{|i-j|}$\n  - $\\text{var}(\\epsilon_i) = \\sigma_{\\epsilon}^2 = \\frac{\\sigma^2}{1- \\sigma^2}$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1_ar1 <- gls(\n  circumference ~ age,\n  data = Orange,\n  correlation = corAR1(form = ~ 1),\n  method = \"ML\"\n)\nmodelo1_ar1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized least squares fit by maximum likelihood\n  Model: circumference ~ age \n  Data: Orange \n  Log-likelihood: -148.6485\n\nCoefficients:\n(Intercept)         age \n24.35977454  0.09860702 \n\nCorrelation Structure: AR(1)\n Formula: ~1 \n Parameter estimate(s):\n      Phi \n0.6799389 \nDegrees of freedom: 35 total; 33 residual\nResidual standard error: 22.86347 \n```\n\n\n:::\n:::\n\n\n\n\n\n### Modelo AR(1) por tipo de árbol\n\n- `corAR1` explanation:\n  - $\\text{var}(\\epsilon_{ij}) = \\sigma_{\\epsilon_j}^2 = \\frac{\\sigma}{1 - \\rho_j^2}$\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo2_ar1 <- gls(\n  circumference ~ age,\n  data = Orange,\n  correlation = corAR1(form = ~ 1 | Tree),\n  method = \"ML\"\n)\nmodelo2_ar1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized least squares fit by maximum likelihood\n  Model: circumference ~ age \n  Data: Orange \n  Log-likelihood: -144.7617\n\nCoefficients:\n(Intercept)         age \n23.58870422  0.09700685 \n\nCorrelation Structure: AR(1)\n Formula: ~1 | Tree \n Parameter estimate(s):\n      Phi \n0.7883439 \nDegrees of freedom: 35 total; 33 residual\nResidual standard error: 22.95347 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(modelo2_ar1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized least squares fit by maximum likelihood\n  Model: circumference ~ age \n  Data: Orange \n       AIC      BIC    logLik\n  297.5235 303.7449 -144.7617\n\nCorrelation Structure: AR(1)\n Formula: ~1 | Tree \n Parameter estimate(s):\n      Phi \n0.7883439 \n\nCoefficients:\n                Value Std.Error   t-value p-value\n(Intercept) 23.588704  11.12701  2.119949  0.0416\nage          0.097007   0.00864 11.227809  0.0000\n\n Correlation: \n    (Intr)\nage -0.687\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-1.6142892 -0.5660328 -0.1322463  1.0237556  2.2793020 \n\nResidual standard error: 22.95347 \nDegrees of freedom: 35 total; 33 residual\n```\n\n\n:::\n:::\n\n\n\n\n\n### Comparación con MCO\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_mco <- lm(circumference ~ age, data = Orange, method = \"ML\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in lm(circumference ~ age, data = Orange, method = \"ML\"): method = 'ML'\nis not supported. Using 'qr'\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(modelo_mco, modelo1_wls)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in anova.lmlist(object, ...): models with response '\"NULL\"' removed\nbecause response differs from model 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: circumference\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nage        1  93772   93772  166.42 1.931e-14 ***\nResiduals 33  18595     563                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(modelo_mco, modelo1_ar1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in anova.lmlist(object, ...): models with response '\"NULL\"' removed\nbecause response differs from model 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: circumference\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nage        1  93772   93772  166.42 1.931e-14 ***\nResiduals 33  18595     563                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n## Pruebas de heterocedasticidad y autocorrelación\n\n- **Modelo hetecedástico significa que depende de la observación**.\n\n### Prueba de Breusch-Pagan (homocedasticidad)\n\n- Negar la hipótesis nula implica afirmar, con cierto grado de confianza,\nque la **varianza no es constante entre las observaciones**.\n\n::: {.callout-note}\n### Algoritmo\n\n1. Estimar el modelo por MCO y obtener los residuos $\\hat{\\varepsilon}_i$.\n\n2. Calcular los residuos al cuadrado: $\\hat{u}_i = \\hat{\\varepsilon}_i^2$.\n\n3. Ajustar la siguiente regresión auxiliar: $\\hat{u}_i = \\alpha_0 + \\alpha_1 x_{i1} + \\cdots + \\alpha_k x_{ik} + v_i$, y calcular el coeficiente de determinación $R^2$ de dicha regresión.\n\n4. Calcular el estadístico de prueba de Breusch-Pagan:\n\n$$\n\\text{BP} = nR^2 \\xrightarrow{D} \\chi_k^2 \\qquad (1)\n$$\n\nSe rechaza la hipótesis nula de homocedasticidad si:\n\n$$\n\\text{BP} > \\chi_{k,1-\\alpha}^2\n$$\n:::\n\n\n### Prueba de Durbin-Watson (autocorrelación)\n\n$$\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_k x_{ik} + \\varepsilon_i, \\quad i = 1, \\ldots, n,\n$$\n\ndonde se asume que los errores $\\varepsilon_i$ son no correlacionados y con media cero: $\\mathbb{E}[\\varepsilon_i] = 0$ y $\\text{Cov}(\\varepsilon_i, \\varepsilon_j) = 0$ para $i \\neq j$.\n\n- $H_0: \\rho = 0$ o equivale a decir $\\text{Cov}(\\varepsilon_i, \\varepsilon_{i-1}) = 0$ $\\forall i$\n\n- $H_1: \\rho \\neq 0$ (o bien $\\rho > 0$ si se sospecha autocorrelación positiva)\n\nSea $\\hat{\\varepsilon}_i$ el residuo del modelo estimado por mínimos cuadrados ordinarios.\n\n$$\nDW = \\frac{\\sum_{i=2}^n (\\hat{\\varepsilon}_i - \\hat{\\varepsilon}_{i-1})^2}{\\sum_{i=1}^n \\hat{\\varepsilon}_i^2}. \\qquad (2)\n$$\n\nEl valor del estadístico $DW$ se encuentra en el intervalo $[0, 4]$, con la siguiente interpretación:\n\n- $DW \\approx 2$: no hay autocorrelación.\n\n- $DW < 2$: indicio de autocorrelación positiva.\n\n- $DW > 2$: indicio de autocorrelación negativa.\n\nSe compara el valor observado de $DW$ con los valores críticos $d_L$ (límite inferior) y $d_U$ (límite superior), determinados por tablas específicas según $n$ y $k$.\n\n| Condición sobre $DW$                    | Conclusión                                |\n|----------------------------------------|-------------------------------------------|\n| $DW < d_L$                              | Hay evidencia de autocorrelación positiva |\n| $d_L \\leq DW \\leq d_U$                  | Resultado inconcluso                      |\n| $d_U < DW < 4 - d_U$                    | No hay evidencia de autocorrelación       |\n| $4 - d_U \\leq DW \\leq 4 - d_L$          | Resultado inconcluso                      |\n| $DW > 4 - d_L$                          | Hay evidencia de autocorrelación negativa |\n\n: Regla de decisión para el estadístico de Durbin-Watson\n\n## Ejercicio y aplicación\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: zoo\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'zoo'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n\n```{.r .cell-code}\ndata(cars)\n\nplot(\n  cars$speed,\n  cars$dist,\n  xlab = \"Velocidad (mph)\",\n  ylab = \"Distancia de frenado (ft)\",\n  pch = 16,\n  col = \"blue\"\n)\n```\n\n::: {.cell-output-display}\n![](clase-10_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Modelo clásico MCO\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1_ols <- lm(dist ~ speed, data = cars)\nsummary(modelo1_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nspeed         3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,\tAdjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- resid(modelo1_ols)**2\nx <- cars$speed\nmod0 <- lm(y ~ x)\nn <- length(y)\nBP <- n*summary(mod0)$r.squared\nalpha <- 0.05\n\n# X_1-alpha,k\nqchi <- qchisq(1-alpha, 1) \n\n# Se rechaza si\n(BP > qchi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbptest(modelo1_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  modelo1_ols\nBP = 3.2149, df = 1, p-value = 0.07297\n```\n\n\n:::\n:::\n\n\n\n\n\n- **Interpretación**: No existe evidencia suficiente para rechazar la hipótesis de\nhomocedasticidad para este conjunto de datos. En ese sentido, ajustar los datos\na un modelo heterocedástico no resultaría conveniente.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(Orange)\nplot(\n  Orange$age, Orange$circumference,\n  xlab = \"Edad del árbol\",\n  ylab = \"Circunferencia\",\n  pch = 16,\n  col = \"blue\"\n)\n```\n\n::: {.cell-output-display}\n![](clase-10_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Modelo clasico MCO para Datos 2\nmodelo2_ols <- lm(circumference ~ age, data = Orange)\nsummary(modelo2_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = circumference ~ age, data = Orange)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.310 -14.946  -0.076  19.697  45.111 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17.399650   8.622660   2.018   0.0518 .  \nage          0.106770   0.008277  12.900 1.93e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.74 on 33 degrees of freedom\nMultiple R-squared:  0.8345,\tAdjusted R-squared:  0.8295 \nF-statistic: 166.4 on 1 and 33 DF,  p-value: 1.931e-14\n```\n\n\n:::\n\n```{.r .cell-code}\n## test de Breusch-Pagan para Datos 1\nlibrary(lmtest)\nbptest(modelo2_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  modelo2_ols\nBP = 11.228, df = 1, p-value = 0.0008056\n```\n\n\n:::\n:::\n\n\n\n\n\n- **Interpretación**: Existe suficiente evidencia para concluir que resulta\nuna mejor opción emplear modelos heterocedásticos para este conjunto de datos.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1_wls <- gls(\n  circumference ~ age,\n  data = Orange,\n  weights = varPower(form = ~ age),\n  method = \"ML\"\n)\n\n#Visualización de los modelos\nplot(\n  Orange$age,\n  Orange$circumference,\n  xlab = \"Edad del árbol\",\n  ylab = \"Circunferencia\",\n  pch = 16, \n  col = \"blue\"\n)\nlegend(\"topleft\", legend = c(\"MCO\", \"GLS WLS\"), col = c(\"red\", \"darkgreen\"), lwd = 2)\n\n# Línea MCO\nabline(modelo2_ols, col = \"red\", lwd = 2)\n# Línea GLS\nlines(Orange$age, predict(modelo1_wls), col = \"darkgreen\", lwd = 2)  \n```\n\n::: {.cell-output-display}\n![](clase-10_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Prueba de autocorrelación\n\n**Si hay picos en lag=0 y lag=1, AR(1) es plausible.**\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1_ols <- lm(dist ~ speed, data = cars)\nacf(residuals(modelo1_ols)) \n```\n\n::: {.cell-output-display}\n![](clase-10_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n\n**Si hay picos a partir de lag=1**, es posible exista evidencia de autocorrelación.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmtest::dwtest(modelo1_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDurbin-Watson test\n\ndata:  modelo1_ols\nDW = 1.6762, p-value = 0.09522\nalternative hypothesis: true autocorrelation is greater than 0\n```\n\n\n:::\n:::\n\n\n\n\n\n**Interpretación**: No hay suficiente evidencia para afirmar que no hay autocorrelación.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(Orange)\nmodelo2_ols <- lm(circumference ~ age, data = Orange)\nsummary(modelo2_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = circumference ~ age, data = Orange)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.310 -14.946  -0.076  19.697  45.111 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17.399650   8.622660   2.018   0.0518 .  \nage          0.106770   0.008277  12.900 1.93e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.74 on 33 degrees of freedom\nMultiple R-squared:  0.8345,\tAdjusted R-squared:  0.8295 \nF-statistic: 166.4 on 1 and 33 DF,  p-value: 1.931e-14\n```\n\n\n:::\n\n```{.r .cell-code}\nacf(residuals(modelo2_ols))\n```\n\n::: {.cell-output-display}\n![](clase-10_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(lmtest)\nlmtest::dwtest(modelo2_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDurbin-Watson test\n\ndata:  modelo2_ols\nDW = 0.66953, p-value = 2.392e-06\nalternative hypothesis: true autocorrelation is greater than 0\n```\n\n\n:::\n:::\n\n\n\n\n\n**Interpretación**: Hay suficiente evidencia para afirmar que existe autocorrelación.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelo AR(1)\nmodelo1_ar1 <- gls(\n  circumference ~ age,\n  data = Orange,\n  correlation = corAR1(form = ~ 1),\n  method = \"ML\"\n)\n\n#Visualización de los modelos\nplot(\n  Orange$age, Orange$circumference, \n  xlab = \"Edad del árbol\",\n  ylab = \"Circunferencia\",\n  pch = 16, col = \"blue\"\n)\nlegend(\"topleft\", legend = c(\"MCO\", \"GLS AR1\"), col = c(\"red\", \"darkgreen\"), lwd = 2)\n\n# Línea MCO\nabline(modelo2_ols, col = \"red\", lwd = 2)          \n# Línea GLS\nlines(Orange$age, predict(modelo1_ar1), col = \"darkgreen\", lwd = 2)  \n```\n\n::: {.cell-output-display}\n![](clase-10_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::",
    "supporting": [
      "clase-10_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}